---


title: 节点检测
date: 2022-03-26 10:34:00 +0800
categories: [随笔]
tags: [分类]
pin: true
author: 刘德智

toc: true
comments: true
typora-root-url: ../../liudezhiya.github.io
math: false
mermaid: true
---

[TOC]

### 1.产生所需文件

#### ① 选择安全,项目中含有安全的

输入：alldata_award_' + year + '.csv

输出：NamePaperProject_safe.csv

```python
def choice_safe():
    # #① 选择安全,项目中含有安全的
    f2 = open('G://data//findnodeoutput//NamePaperProject_safe.csv', 'w', encoding='utf-8', newline='')
    writer = csv.writer(f2)
    # 指定文件列名
    writer.writerow(
        ['p_index', 'alldata_uuid', 'proJName', 'projId', 'typeCode', 'projType', 'admin', 'supportNum', 'timeScope',
         'approveYear', 'finishYear', 'dependUnit', 'keyWords', 'abstractCh', 'abstractEn', 'conclusionAbstract',
         'alldatafilename', 'alldatafileid', 'index', 'award_uuid', 'award_name', 'award_type', 'authors', 'unknown',
         'awardfilename'])
    for year in range(2018, 2022):
        print('**************************************************', year,'*********************************************')
        year = str(year)
        csv_reader = csv.reader(
            open('G://BaiduNetdiskDownload//135数据//18-22文件合并//' + year + '//alldata_award_' + year + '.csv',
                 encoding='utf-8'))
        for row in csv_reader:
            if row[1] == '':
                print('==============================')
                print(row)
                continue
            if '安全' in row[2]:
                writer.writerow(row)
                print(row[2])
    f2.close()
```

输出文件NamePaperProject_safe.csv文件

![](/../blog/assets/blog_res/2022-09-10-节点检测/safe.png)

#### ②拆分论文作者

输入：NamePaperProject_safe.csv

输出：Name2Paper2Project_safe.csv

```python
def namesplit():
    ##②将合并后提取出来的安全作者拆分 生成所需字段
    alldata_award = 'G://data//findnodeoutput//NamePaperProject_safe.csv'
    info = pd.read_csv(alldata_award, encoding='utf-8')
    info = info[
        ['proJName', 'projId', 'typeCode', 'projType', 'admin', 'approveYear', 'finishYear', 'dependUnit', 'keyWords',
         'award_type', 'authors']]
    info_new = info.drop(['authors'], axis=1).join(
        info['authors'].str.split(';', expand=True).stack().reset_index(level=1, drop=True).rename('author'))
    info_new = info_new.reset_index()
    info_new['id'] = info_new['dependUnit'] + ' ' + info_new['author']
    info_new.to_csv('G://data//findnodeoutput//Name2Paper2Project_safe.csv', index=None)
```

输出Name2Paper2Project_safe.csv文件

<img src="/../blog/assets/blog_res/2022-09-10-节点检测/namesplit.png" style="zoom:33%;" />

#### ③产生节点字典

输入：Name2Paper2Project_safe.csv

输出：index2name.txt，name2index.txt

方法一

```python
def gen_node_dict():
    ##③产生节点字典
    # 产生index2name字典
    alldata_award = 'G://data//findnodeoutput//Name2Paper2Project_safe.csv'
    info = pd.read_csv(alldata_award, encoding='utf-8')
    info = info['id'].drop_duplicates()
    with open('G://data//findnodeoutput//index2name.txt', 'w', encoding='utf-8') as f:
        index2name = info.to_dict()
        f.write(str(index2name))
    # 产生name2index字典
    name2index = dict((v, k) for k, v in index2name.items())
    with open('G://data//findnodeoutput//name2index.txt', 'w', encoding='utf-8') as f:
        name2index = info.to_dict()
        f.write(str(name2index))
```

输出index2name.txt，name2index.txt文件

<img src="/../blog/assets/blog_res/2022-09-10-节点检测/indexname.png" style="zoom: 33%;" />

<img src="/../blog/assets/blog_res/2022-09-10-节点检测/nameindex.png" style="zoom: 33%;" />

### 2.拆分年份

输入：Name2Paper2Project_safe.csv

输出：Paper2node+ time + .txt  (2013-2020年)

直接文件生成字典，避免读写文件

```python
#节点转化字典
def nameIndexDict():
    alldata_award = 'G://data//findnodeoutput//Name2Paper2Project_safe.csv'
    info = pd.read_csv(alldata_award, encoding='utf-8')
    info = info['id'].drop_duplicates()
    index2name = info.to_dict()
    nameDict = dict((v, k) for k, v in index2name.items())
    return index2name,nameDict

```

```python
def yearSplit(begin,end,nameDict):
    for time in range(begin, end):
        print(time)
        projectDict = {}
        csv_reader = csv.reader(open("G://data//findnodeoutput//Name2Paper2Project_safe.csv", encoding='utf-8'))
        with open('G://data//findnodeoutput//Paper2node' + str(time) + '.txt', 'w', encoding='utf-8') as f1:  # 生成文件
            for row in csv_reader:
                if str(time - 1) > row[6] or row[6] > str(time + 1) or row[14] == '':  # 其他情况
                    continue
                id = nameDict[row[14]]
                if row[10] not in projectDict and row[10] != '':
                    projectDict[row[10]] = [id]
                else:
                    projectDict[row[10]].append(id)
            print(projectDict)
            f1.write(str(projectDict))
```

年份构成

<img src="/../blog/assets/blog_res/2022-09-10-节点检测/splityear.png" style="zoom: 50%;" />

输出Paper2node+ time + .txt文件

![](/../blog/assets/blog_res/2022-09-10-节点检测/yearnode.png)



### 3.构建网络(论文作者合作关系)

输入：Name2Paper2Project_safe.csv

输出：PaperEdge + time + .txt

```python
def genNetwork(begin,end):
    # 构建网络(论文作者合作关系)
    allauthornum = []
    alledgenum = []
    for time in range(begin, end):
        print(time)
        paperEdge = {}
        author_cu = 0
        edge_cu = 0
        with open('Paper2node' + str(time) + '.txt', 'r', encoding='utf-8') as f1:
            data = f1.read()
            authorList = eval(data)
        for value in authorList.values():
            print(value)
            for i in value:  # [10, 11, 12, 8, 9, 3]
                # print(i)
                tmp1 = list(value)
                tmp1.remove(i)
                if i not in paperEdge.keys():
                    author_cu += 1
                    paperEdge[i] = tmp1  # 10：[11, 12, 8, 9, 3]
                else:
                    tmp2 = paperEdge[i]
                    print(paperEdge[i])
                    paperEdge[i] = list(set(tmp2 + tmp1))
        print(paperEdge)
        for i in paperEdge:
            author_cu += 1
            edge_cu += len(paperEdge[i])
        allauthornum.append(author_cu)
        alledgenum.append(edge_cu)

        with open('G://data//findnodeoutput//PaperEdge' + str(time) + '.txt', 'w', encoding='utf-8') as f2:
            f2.write(str(paperEdge))
    print(alledgenum)
    print(allauthornum)
```

输出PaperEdge + time + .txt文件

<img src="/../blog/assets/blog_res/2022-09-10-节点检测/paperedge.png" style="zoom:50%;" />

### 4.计算节点论文每一年的count值

输入：Name2Paper2Project_safe.csv

输出：PaperCountDict.txt

```python
def yearcount(year):
    if year == "2013":
        return 0
    if year == "2014":
        return 1
    if year == "2015":
        return 2
    if year == "2016":
        return 3
    if year == "2017":
        return 4
    if year == "2018":
        return 5
    if year == "2019":
        return 6
    if year == "2020":
        return 7

def paperCount(nameDict):
    csv_reader = csv.reader(open("G://data//findnodeoutput//Name2Paper2Project_safe.csv", encoding='utf-8'))
    countDict = {}
    with open('G://data//findnodeoutput//PaperCountDict.txt', 'w', encoding='utf-8') as f2:
        for row in csv_reader:
            if row[14] != '' and row[14] != 'id':  # 列名
                id = nameDict[row[14]]
                year = row[6]
                numlocal = yearcount(year)
                if id not in countDict:
                    countDict[id] = [0, 0, 0, 0, 0, 0, 0, 0]
                countDict[id][numlocal] += 1
        print(countDict)
        f2.write(str(countDict))
```

输出：PaperCountDict.txt文件

<img src="/../blog/assets/blog_res/2022-09-10-节点检测/papercount.png" style="zoom:50%;" />

### 5.为每个网络节点计算p - 值

输入：PaperCountDict.txt	

输出：paper_pvalue_+ year+ .txt

```python
def mathPValues():
    # 第二步：为每个网络节点计算p-值13-20年->17-20
    with open('G://data//findnodeoutput//PaperCountDict.txt', 'r', encoding='utf-8') as f8:
        data = f8.read()
        paperCount = eval(data)
    for year in range(2017, 2021):
        paperPValueDict = {}
        learn_len = year - 2013 + 1
        for key, value in paperCount.items():
            p_count = 0
            for i in range(learn_len):
                if value[i] <= mean(value[:i + 1]):
                    p_count += 1
            pvalue = (p_count - 1) / len(value)
            paperPValueDict[key] = pvalue
        num = 0
        # 统计了异常的人数
        for key, value in paperPValueDict.items():
            if value <= 0.15:
                num += 1
        print(year)
        print(num)
        with open('G://data//findnodeoutput//paper_pvalue_' + str(year) + '.txt', 'w', encoding='utf-8') as f9:
            f9.write(str(paperPValueDict))
```

输出paper_pvalue_+ year+ .txt文件

![](/../blog/assets/blog_res/2022-09-10-节点检测/pvalues.png)

### 6.统计异常机构和异常人员名单

输入：paper_pvalue_+year+.txt  ,  Name2Paper2Project_safe.csv

输出：peojectYiChangMinDan+year+.txt ,  paper_YiChang_school+year+.txt , allschool.txt

```python
###生成异常机构和异常人员名单
def distinguished(id2name):
    all_school = []
    for year in range(2017, 2021):
        with open('G://data//findnodeoutput//paper_pvalue_' + str(year) + '.txt', 'r') as pvalue_file:
            p_value = eval(pvalue_file.read())
            pvalue_file.close()
        num = 0
        nameDict = {}
        schooldict = {}
        count = 0
        # 统计网络中的异常点{人名+机构名：[id,p值]}
        for key, value in p_value.items():
            if value <= 0.15:
                nameschool = id2name[key]
                if nameschool not in nameDict:
                    num += 1
                    currentnume = nameschool
                    nameDict[nameschool] = [key, value]
                    school = nameschool.split(" ")[-1]
                    all_school.append(school)
                    if school not in schooldict:
                        # if school not in schooldict:
                        schooldict[school] = 1
                    else:
                        schooldict[school] += 1
        print("一共 " + str(num) + " 的优秀人才")
        print(schooldict)
        with open('G://data//findnodeoutput//peojectYiChangMinDan' + str(year) + '.txt', 'w', encoding='utf-8') as f5:
            f5.write(str(nameDict))
        with open('G://data//findnodeoutput//paper_YiChang_school' + str(year) + '.txt', 'w', encoding='utf-8') as f5:
            f5.write(str(schooldict))
    all_school = list(set(all_school))
    with open('G://data//findnodeoutput//allschool.txt', 'w', encoding='utf-8') as f5:
        f5.write(str(all_school))
```

输出文件

peojectYiChangMinDan+year+.txt 

![](/../blog/assets/blog_res/2022-09-10-节点检测/ycmd.png)

paper_YiChang_school+year+.txt 

![](/../blog/assets/blog_res/2022-09-10-节点检测/ycschool.png)

allschool.txt

![](/../blog/assets/blog_res/2022-09-10-节点检测/allschool.png)



### 7.p值分布excel表格生成

输入：allschool.txt   ,    paper_YiChang_school+year)+.txt

输出：数据表.xls

```python
####绘制p值分布excel表格生成
import xlwt
import re
def writeinexcel1():
    f = open('G://data//findnodeoutput//paper_YiChang_school2017.txt', 'r', encoding='utf-8')  # 打开数据文本文档，注意编码格式的影响
    wb = xlwt.Workbook(encoding='utf-8')  # 新建一个excel文件
    ws1 = wb.add_sheet('first')  # 添加一个新表，名字为first
    ws1.write(0, 0, 'school')
    ws1.write(0, 1, 2017)
    ws1.write(0, 2, 2018)
    ws1.write(0, 3, 2019)
    ws1.write(0, 4, 2020)
    row = 1  # 写入的起始行
    col = 0  # 写入的起始列
    # 通过row和col的变化实现指向单元格位置的变化
    k = 1
    allschool={}
    with open('G://data//findnodeoutput//allschool.txt', 'r', encoding='UTF-8-sig') as pvalue_file:
        lines = pvalue_file.read()
        a = lines.split(',')
        for i in range(len(a)):
            current_a=re.sub("'", "", a[i])
            current_a = re.sub(" ", "", current_a)
            print(current_a)
            yearn = dict()
            for year in range(2017,2021):
                with open('G://data//findnodeoutput//paper_YiChang_school'+str(year)+'.txt', 'r', encoding='UTF-8-sig') as pvalue_file2:
                    p_value = eval(pvalue_file2.read())
                    pvalue_file2.close()
                    print(p_value)
                    if current_a in p_value:
                        # print("ll")
                        yearn[year]= p_value[current_a]
                    else:
                        yearn[year] =int(0)
            allschool[current_a] = yearn
    for key,values in allschool.items():
        ws1.write(row, col, key)
        col+=1
        for key2,x in values.items():
            ws1.write(row, col, x)  # 向Excel文件中写入每一项
            col += 1
        row += 1
        col = 0

    wb.save("G://data//findnodeoutput//数据表.xls")
```

输出数据表.xls文件

![](/../blog/assets/blog_res/2022-09-10-节点检测/shujubiao.png)

#### 算法部分完

### 8.期刊类型分布excel表格生成

输入：Name2Paper2Project_safe.csv

输出：journal.xls

```python
####绘制期刊值分布excel表格生成
import xlwt
import re
def writeinexcel2():
    csv_reader = csv.reader(open("G://data//findnodeoutput//Name2Paper2Project_safe.csv",encoding='utf-8'))
    dict_c={}
    for row in csv_reader:
        if row[16] in dict_c.keys():
            dict_c[row[16]]+=1
        else:
            dict_c[row[16]] = 1

    wb = xlwt.Workbook(encoding='utf-8')  # 新建一个excel文件
    ws1 = wb.add_sheet('first')  # 添加一个新表，名字为first
    ws1.write(0, 0, 'journal')
    ws1.write(0, 1, 'num')
    row = 1  # 写入的起始行
    col = 0  # 写入的起始列
    # 通过row和col的变化实现指向单元格位置的变化
    k = 1
    for key,values in dict_c.items():
        ws1.write(row, col, key)
        col+=1
        ws1.write(row, col, values)  # 向Excel文件中写入每一项
        row += 1
        col = 0

    wb.save("G://data//findnodeoutput//journal.xls")
```

输出journal.xls文件

![](/../blog/assets/blog_res/2022-09-10-节点检测/jouenal.png)

### main函数

```python
if __name__ == '__main__':
    ##1.产生所需文件
    ## ①选择项目中含有安全的
    choice_safe()
    ##②拆分论文作者
    namesplit()
    ##③产生节点字典
    gen_node_dict()
    ##③节点转化字典
    index2name,nameDict=nameIndexDict()
    
    ##2.拆分年份
    yearSplit(2013, 2021, nameDict)
    
    # 多时间片网络
    ##3.构建网络(论文作者合作关系)
    genNetwork(2013,2021)

    ##按照时间片划分数据，每一年划分一个数据集。计算节点的异常度。
    ## 4.第一步计算节点论文的count值,格式“id : [count1,count2,...,count7]”
    paperCount(nameDict)
    
    ##5.为每个网络节点计算p - 值
    mathPValues()
    
    ##6.统计异常机构和异常人员名单
    distinguished(index2name)
    
    ##7.绘制p值分布excel表格生成
    writeinexcel1()
    
    ##8.绘制奖励类型分布excel表格生成
    writeinexcel2()
```

