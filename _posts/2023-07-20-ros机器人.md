# 培训内容

ROS和人工智能技术的实训

![image-20230722094456043](C:\Users\24514\AppData\Roaming\Typora\typora-user-images\image-20230722094456043.png)



![image-20230722094513430](C:\Users\24514\AppData\Roaming\Typora\typora-user-images\image-20230722094513430.png)











# 实现

```python
import cv2 
import numpy as np
import time
import rospy
import tf
import threading
import numpy as np
import math
from math import sqrt
from geometry_msgs.msg import PoseWithCovarianceStamped
from ar_track_alvar_msgs.msg import AlvarMarkers
from ar_track_alvar_msgs.msg import AlvarMarker
import CMDcontrol
import requests
# 动作执行函数
def action(act_name):
    print(f'执行动作: {act_name}')
    time.sleep(1)
    CMDcontrol.action_append(act_name)
def init_action_thread():
    th2 = threading.Thread(target=thread_move_action) # 创建线程
    th2.setDaemon(True)
    th2.start()
def thread_move_action():
    CMDcontrol.CMD_transfer() # 调用底层命令转发函数
# 摄像头图片获取url
ur1='http://192.168.3.154:8080/snapshot?topic=/usb_cam_chest/image_raw'
# 机器人控制函数
def move_forward():
    print("Moving forward")
    action("forwalk6") # 调用前进动作
def turn_left_1():
    print("Turning left 较小")
    action("turnleft") # 调用小幅左转动作
def turn_left_2():
    print("Turning left 一般")
    action("turnleft") # 调用中等幅左转动作
def turn_left_3():
    print("Turning left 大")
    action("turn010L") # 调用大幅左转动作
def turn_right_1():
    print("Turning right 较小")
    action("turnright") # 调用小幅右转动作
def turn_right_2():
    print("Turning right 一般")
    action("turnright") # 调用中等幅右转动作
def turn_right_3():
    print("Turning right 大")
    action("turn010R") # 调用大幅右转动作
def stop():
    print("Stopping")
    action("stop") # 调用停止动作
# 初始化动作执行线程
init_action_thread()
time.sleep(1)
# 主程序
def main():
    i=1
    while True:
        # 获取图像
        path = 'img/img' + str(i) + '.jpg' 
        pic=requests.get(ur1)
        fp=open(path,'wb')
        fp.write(pic.content)
        fp.close()
        img=cv2.imread(path)
        # 图像预处理
        img=np.rot90(img, -1)   
        img=img[30:180,10:470]
        cv2.imwrite(path, img)
		i += 1
        # 图像处理
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)#灰度处理
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        #使用 cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY) 对灰度图像进行二值化处理。
        #这里使用了阈值为100的简单二值化方法，将大于阈值的像素设为255（白色），小于阈值的像素设为0（黑色），这样得到名为 binary 的二值图像。

        # 寻找黑色线条轮廓
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
		#cv2.RETR_EXTERNAL 表示只检测外部轮廓，即只寻找图像边缘的轮廓。
        # cv2.CHAIN_APPROX_SIMPLE 表示对轮廓进行简化，只保留轮廓的端点信息，省略其中的中间点，以减少内存消耗
        #cv2.findContours() 函数会返回两个值：
        # contours 是一个包含所有轮廓的列表。每个轮廓都是一个数组，其中包含轮廓上的所有点的坐标。
        '''
                         # 绘制轮廓
        cv2.drawContours(frame, contours, -1, (0, 255, 0), 2)

        # 显示图像和结果
        cv2.imshow("Frame", frame)
        cv2.imshow("Threshold", binary)'''
        #cv2.imshow("Threshold", binary)
        #cv2.waitKey(60)
        # 根据轮廓控制机器人
        if len(contours) > 0:
            # 找到最大的轮廓
            max_contour = max(contours, key=cv2.contourArea)#contourArea计算轮廓面积
            #使用 cv2.boundingRect(max_contour) 函数计算最大轮廓的边界矩形。
            #返回的 x 和 y 是边界矩形的左上角坐标，而 w 和 h 是矩形的宽度和高度。
            x, y, w, h = cv2.boundingRect(max_contour)
            # 根据中心点位置判断转向
            if img.shape[1]*0.35<center_x < img.shape[1] * 0.5 - 40:
                turn_left_1()
            elif img.shape[1]*0.65>center_x > img.shape[1] *0.5 + 40:
                turn_right_1()
            if img.shape[1]*0.15<center_x<img.shape[1]*0.35:
                turn_left_2()
            elif img.shape[1]*0.65<center_x<img.shape[1]*0.85:
                turn_right_2()
            if center_x<img.shape[1]*0.15:
                turn_left_3()
            elif center_x>img.shape[1]*0.85
            {
                turn_right_3()
            }
            else:
                move_forward()
        else:
            stop()
             '''
        这里我们使用 x + w // 2 计算了矩形的中心横坐标。

       最后，根据 center_x 和图像帧的宽度的一半，进行判断机器人应该执行的动作。
       如果 center_x 小于图像帧宽度的一半减去 50，即矩形的中心在图像的左侧，那么机器人应该向左转，调用 turn_left() 函数。
       如果 center_x 大于图像帧宽度的一半加上 50，即矩形的中心在图像的右侧，那么机器人应该向右转，调用 turn_right() 函数。
       如果以上条件都不满足，即矩形的中心在图像的前方范围内，那么机器人应该继续前进，调用 move_forward() 函数。
       通过这样的逻辑判断，可以根据目标物体在图像中的位置来控制机器人的动作，使其朝向目标或者避开障碍物。
        '''
            
        i += 1
        time.sleep(0.5)
        
if __name__ == '__main__':
    main()
```

